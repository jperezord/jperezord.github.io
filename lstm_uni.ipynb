{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM univariate prediction {.unnumbered}\n",
        "\n",
        "Import python packages:"
      ],
      "id": "2d097923"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM"
      ],
      "id": "8d73cc28",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_covid = pd.read_csv('data/clean/final_covid_data.csv')\n",
        "data_covid"
      ],
      "id": "42518f3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# All the available data\n",
        "\n",
        "## Asturias"
      ],
      "id": "5c4a5495"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_asturias = data_covid.loc[data_covid['provincia'] == 'Asturias']\n",
        "data_asturias = data_asturias.set_index('fecha')\n",
        "data_asturias = data_asturias.filter(['num_casos'])\n",
        "data_asturias"
      ],
      "id": "1bce53bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_asturias.describe()"
      ],
      "id": "a5d5f378",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_asturias = data_asturias.values"
      ],
      "id": "b1e953d7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_asturias = scaler.fit_transform(np_data_asturias)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_asturias)}')"
      ],
      "id": "ad7b4a27",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_asturias_x = []\n",
        "scaled_data_asturias_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_asturias)):\n",
        "    scaled_data_asturias_x.append(scaled_data_asturias[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_asturias_y.append(scaled_data_asturias[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_asturias_x = np.array(scaled_data_asturias_x)\n",
        "scaled_data_asturias_y = np.array(scaled_data_asturias_y)"
      ],
      "id": "2474d329",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_asturias_x[235]"
      ],
      "id": "a3df6519",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_asturias_y[235]"
      ],
      "id": "06205a8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_asturias_y)}')"
      ],
      "id": "da6e0692",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_asturias_x[0:len(scaled_data_asturias_x)-22]\n",
        "y_train = scaled_data_asturias_y[0:len(scaled_data_asturias_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_asturias_x[len(scaled_data_asturias_x)-21:len(scaled_data_asturias_x)]\n",
        "y_test = scaled_data_asturias_y[len(scaled_data_asturias_y)-21:len(scaled_data_asturias_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "3761eb59",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "b2b396c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "61a5f6ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "23df6038",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "bb83bd61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "1683dc15",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "d1bb2bd7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "99848e94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_asturias[:(len(x_train)+23)]\n",
        "valid = data_asturias[(len(x_train)+22):]"
      ],
      "id": "64a3cabe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "5e359532",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2022-01-31\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "27d98ee0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Asturias: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "e09e0ec0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Barcelona"
      ],
      "id": "223e1cfb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Barcelona = data_covid.loc[data_covid['provincia'] == 'Barcelona']\n",
        "data_Barcelona = data_Barcelona.set_index('fecha')\n",
        "data_Barcelona = data_Barcelona.filter(['num_casos'])\n",
        "data_Barcelona"
      ],
      "id": "b0bce461",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Barcelona.describe()"
      ],
      "id": "292659f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Barcelona = data_Barcelona.values"
      ],
      "id": "5e7f9201",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Barcelona = scaler.fit_transform(np_data_Barcelona)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Barcelona)}')"
      ],
      "id": "d1c81adf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Barcelona_x = []\n",
        "scaled_data_Barcelona_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Barcelona)):\n",
        "    scaled_data_Barcelona_x.append(scaled_data_Barcelona[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Barcelona_y.append(scaled_data_Barcelona[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Barcelona_x = np.array(scaled_data_Barcelona_x)\n",
        "scaled_data_Barcelona_y = np.array(scaled_data_Barcelona_y)"
      ],
      "id": "bc9ea89b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Barcelona_x[235]"
      ],
      "id": "41206193",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Barcelona_y[235]"
      ],
      "id": "6a9ec853",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Barcelona_y)}')"
      ],
      "id": "0eb7f314",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Barcelona_x[0:len(scaled_data_Barcelona_x)-22]\n",
        "y_train = scaled_data_Barcelona_y[0:len(scaled_data_Barcelona_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Barcelona_x[len(scaled_data_Barcelona_x)-21:len(scaled_data_Barcelona_x)]\n",
        "y_test = scaled_data_Barcelona_y[len(scaled_data_Barcelona_y)-21:len(scaled_data_Barcelona_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "b03d50dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "ca42b384",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "3f355f17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "4ff7e134",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "7f6f6cea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "4875977e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "e9abb815",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "3db9f095",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Barcelona[:(len(x_train)+23)]\n",
        "valid = data_Barcelona[(len(x_train)+22):]"
      ],
      "id": "f5c00023",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "1e0bda12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2022-01-31\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "bf7b3f37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Barcelona: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "3a0dcbd8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Madrid"
      ],
      "id": "8493e5dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Madrid = data_covid.loc[data_covid['provincia'] == 'Madrid']\n",
        "data_Madrid = data_Madrid.set_index('fecha')\n",
        "data_Madrid = data_Madrid.filter(['num_casos'])\n",
        "data_Madrid"
      ],
      "id": "5349ea9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Madrid.describe()"
      ],
      "id": "0b58efe8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Madrid = data_Madrid.values"
      ],
      "id": "067b5ecf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Madrid = scaler.fit_transform(np_data_Madrid)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Madrid)}')"
      ],
      "id": "003ad320",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Madrid_x = []\n",
        "scaled_data_Madrid_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Madrid)):\n",
        "    scaled_data_Madrid_x.append(scaled_data_Madrid[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Madrid_y.append(scaled_data_Madrid[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Madrid_x = np.array(scaled_data_Madrid_x)\n",
        "scaled_data_Madrid_y = np.array(scaled_data_Madrid_y)"
      ],
      "id": "805d1d26",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Madrid_x[235]"
      ],
      "id": "c861de46",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Madrid_y[235]"
      ],
      "id": "30fd99d5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Madrid_y)}')"
      ],
      "id": "ea10b7ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Madrid_x[0:len(scaled_data_Madrid_x)-22]\n",
        "y_train = scaled_data_Madrid_y[0:len(scaled_data_Madrid_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Madrid_x[len(scaled_data_Madrid_x)-21:len(scaled_data_Madrid_x)]\n",
        "y_test = scaled_data_Madrid_y[len(scaled_data_Madrid_y)-21:len(scaled_data_Madrid_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "735eed16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "f294c404",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "38b264bb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "9797c9cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "2887e4c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "1cac8eed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "bb343c50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "ecb845be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Madrid[:(len(x_train)+23)]\n",
        "valid = data_Madrid[(len(x_train)+22):]"
      ],
      "id": "94ffb642",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "6bce9149",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2022-01-31\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "01ab3083",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Madrid: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "3ba2851f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Malaga"
      ],
      "id": "26df5448"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Malaga = data_covid.loc[data_covid['provincia'] == 'Málaga']\n",
        "data_Malaga = data_Malaga.set_index('fecha')\n",
        "data_Malaga = data_Malaga.filter(['num_casos'])\n",
        "data_Malaga"
      ],
      "id": "dde5888d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Malaga.describe()"
      ],
      "id": "81ce7b84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Malaga = data_Malaga.values"
      ],
      "id": "04803860",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Malaga = scaler.fit_transform(np_data_Malaga)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Malaga)}')"
      ],
      "id": "3c9f949b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Malaga_x = []\n",
        "scaled_data_Malaga_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Malaga)):\n",
        "    scaled_data_Malaga_x.append(scaled_data_Malaga[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Malaga_y.append(scaled_data_Malaga[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Malaga_x = np.array(scaled_data_Malaga_x)\n",
        "scaled_data_Malaga_y = np.array(scaled_data_Malaga_y)"
      ],
      "id": "5a094f37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Malaga_x[235]"
      ],
      "id": "15ea23f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Malaga_y[235]"
      ],
      "id": "e270987d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Malaga_y)}')"
      ],
      "id": "f59629cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Malaga_x[0:len(scaled_data_Malaga_x)-22]\n",
        "y_train = scaled_data_Malaga_y[0:len(scaled_data_Malaga_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Malaga_x[len(scaled_data_Malaga_x)-21:len(scaled_data_Malaga_x)]\n",
        "y_test = scaled_data_Malaga_y[len(scaled_data_Malaga_y)-21:len(scaled_data_Malaga_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "46933e14",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "9dcc7b8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "5011687d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "3eb89fe9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "e2b0750a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "f55e0d25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "3d9e8826",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "b9579a76",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Malaga[:(len(x_train)+23)]\n",
        "valid = data_Malaga[(len(x_train)+22):]"
      ],
      "id": "1f3aaf36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "34f62bd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2022-01-31\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "192f3f1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Malaga: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "b1048cf8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sevilla"
      ],
      "id": "c63beeb5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Sevilla = data_covid.loc[data_covid['provincia'] == 'Sevilla']\n",
        "data_Sevilla = data_Sevilla.set_index('fecha')\n",
        "data_Sevilla = data_Sevilla.filter(['num_casos'])\n",
        "data_Sevilla"
      ],
      "id": "cbd56b4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Sevilla.describe()"
      ],
      "id": "a2e9c3a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Sevilla = data_Sevilla.values"
      ],
      "id": "a361c92b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Sevilla = scaler.fit_transform(np_data_Sevilla)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Sevilla)}')"
      ],
      "id": "6759ac24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Sevilla_x = []\n",
        "scaled_data_Sevilla_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Sevilla)):\n",
        "    scaled_data_Sevilla_x.append(scaled_data_Sevilla[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Sevilla_y.append(scaled_data_Sevilla[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Sevilla_x = np.array(scaled_data_Sevilla_x)\n",
        "scaled_data_Sevilla_y = np.array(scaled_data_Sevilla_y)"
      ],
      "id": "57481509",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Sevilla_x[235]"
      ],
      "id": "238ef332",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Sevilla_y[235]"
      ],
      "id": "f3a5bc3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Sevilla_y)}')"
      ],
      "id": "70e2b6dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Sevilla_x[0:len(scaled_data_Sevilla_x)-22]\n",
        "y_train = scaled_data_Sevilla_y[0:len(scaled_data_Sevilla_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Sevilla_x[len(scaled_data_Sevilla_x)-21:len(scaled_data_Sevilla_x)]\n",
        "y_test = scaled_data_Sevilla_y[len(scaled_data_Sevilla_y)-21:len(scaled_data_Sevilla_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "d6cef92d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "26ef4eeb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "63a43752",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "bf6b27be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "8444ae55",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "caafece8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "e1f48cc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "fb0ffcef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Sevilla[:(len(x_train)+23)]\n",
        "valid = data_Sevilla[(len(x_train)+22):]"
      ],
      "id": "cb793a5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "855158bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2022-01-31\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "bd404e29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Sevilla: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "dea0270b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Just before the sixth wave\n",
        "\n",
        "## Asturias"
      ],
      "id": "d402123a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_asturias = data_covid.loc[data_covid['provincia'] == 'Asturias']\n",
        "data_asturias = data_asturias.set_index('fecha')\n",
        "data_asturias = data_asturias.filter(['num_casos'])\n",
        "data_asturias = data_asturias[data_asturias.index < \"2021-12-31\"]\n",
        "data_asturias"
      ],
      "id": "73d12176",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_asturias.describe()"
      ],
      "id": "4ac4b5c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_asturias = data_asturias.values"
      ],
      "id": "0b7ea3e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_asturias = scaler.fit_transform(np_data_asturias)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_asturias)}')"
      ],
      "id": "e189b60b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_asturias_x = []\n",
        "scaled_data_asturias_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_asturias)):\n",
        "    scaled_data_asturias_x.append(scaled_data_asturias[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_asturias_y.append(scaled_data_asturias[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_asturias_x = np.array(scaled_data_asturias_x)\n",
        "scaled_data_asturias_y = np.array(scaled_data_asturias_y)"
      ],
      "id": "44d86372",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_asturias_x[235]"
      ],
      "id": "eeb15e63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_asturias_y[235]"
      ],
      "id": "0dc1d96b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_asturias_y)}')"
      ],
      "id": "116d81e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_asturias_x[0:len(scaled_data_asturias_x)-22]\n",
        "y_train = scaled_data_asturias_y[0:len(scaled_data_asturias_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_asturias_x[len(scaled_data_asturias_x)-21:len(scaled_data_asturias_x)]\n",
        "y_test = scaled_data_asturias_y[len(scaled_data_asturias_y)-21:len(scaled_data_asturias_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "e67a57c1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "26647076",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "4d23ffc8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "8c2d2be8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "aa96cb5a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "8eecec02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "d5f7d85e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "95bdcb2d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_asturias[:(len(x_train)+23)]\n",
        "valid = data_asturias[(len(x_train)+22):]"
      ],
      "id": "4ea2ae4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "70d0e30b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2021-10-15\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "ca87ee54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Asturias: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "783312fc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Barcelona"
      ],
      "id": "9afe203c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Barcelona = data_covid.loc[data_covid['provincia'] == 'Barcelona']\n",
        "data_Barcelona = data_Barcelona.set_index('fecha')\n",
        "data_Barcelona = data_Barcelona.filter(['num_casos'])\n",
        "data_Barcelona = data_Barcelona[data_Barcelona.index < \"2021-12-31\"]\n",
        "data_Barcelona"
      ],
      "id": "54803242",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Barcelona.describe()"
      ],
      "id": "53f6d56c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Barcelona = data_Barcelona.values"
      ],
      "id": "ac6e5ca8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Barcelona = scaler.fit_transform(np_data_Barcelona)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Barcelona)}')"
      ],
      "id": "27c41d54",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Barcelona_x = []\n",
        "scaled_data_Barcelona_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Barcelona)):\n",
        "    scaled_data_Barcelona_x.append(scaled_data_Barcelona[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Barcelona_y.append(scaled_data_Barcelona[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Barcelona_x = np.array(scaled_data_Barcelona_x)\n",
        "scaled_data_Barcelona_y = np.array(scaled_data_Barcelona_y)"
      ],
      "id": "688fc824",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Barcelona_x[235]"
      ],
      "id": "ced1fc28",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Barcelona_y[235]"
      ],
      "id": "bb503dc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Barcelona_y)}')"
      ],
      "id": "c3df1778",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Barcelona_x[0:len(scaled_data_Barcelona_x)-22]\n",
        "y_train = scaled_data_Barcelona_y[0:len(scaled_data_Barcelona_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Barcelona_x[len(scaled_data_Barcelona_x)-21:len(scaled_data_Barcelona_x)]\n",
        "y_test = scaled_data_Barcelona_y[len(scaled_data_Barcelona_y)-21:len(scaled_data_Barcelona_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "947922a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "cc63e598",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "ecb9fd8a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "8c9e48e4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "db9b3664",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "c13b8e5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "89ebb0f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "18c3a376",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Barcelona[:(len(x_train)+23)]\n",
        "valid = data_Barcelona[(len(x_train)+22):]"
      ],
      "id": "d8907a19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "40290af3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2021-10-15\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "0c7fbdb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Barcelona: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "bdc34cdb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Madrid"
      ],
      "id": "af937839"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Madrid = data_covid.loc[data_covid['provincia'] == 'Madrid']\n",
        "data_Madrid = data_Madrid.set_index('fecha')\n",
        "data_Madrid = data_Madrid.filter(['num_casos'])\n",
        "data_Madrid = data_Madrid[data_Madrid.index < \"2021-12-31\"]\n",
        "data_Madrid"
      ],
      "id": "5bfe431c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Madrid.describe()"
      ],
      "id": "94ed8452",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Madrid = data_Madrid.values"
      ],
      "id": "19f43bd7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Madrid = scaler.fit_transform(np_data_Madrid)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Madrid)}')"
      ],
      "id": "0bbb4759",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Madrid_x = []\n",
        "scaled_data_Madrid_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Madrid)):\n",
        "    scaled_data_Madrid_x.append(scaled_data_Madrid[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Madrid_y.append(scaled_data_Madrid[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Madrid_x = np.array(scaled_data_Madrid_x)\n",
        "scaled_data_Madrid_y = np.array(scaled_data_Madrid_y)"
      ],
      "id": "73f5d339",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Madrid_x[235]"
      ],
      "id": "33ede828",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Madrid_y[235]"
      ],
      "id": "18f18d7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Madrid_y)}')"
      ],
      "id": "ca8b177c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Madrid_x[0:len(scaled_data_Madrid_x)-22]\n",
        "y_train = scaled_data_Madrid_y[0:len(scaled_data_Madrid_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Madrid_x[len(scaled_data_Madrid_x)-21:len(scaled_data_Madrid_x)]\n",
        "y_test = scaled_data_Madrid_y[len(scaled_data_Madrid_y)-21:len(scaled_data_Madrid_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "f4ce00d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "c3a8ba17",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "9614b863",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "1cb28674",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "2f51a9f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "40d642ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "aae3f738",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "6dd3a3a9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Madrid[:(len(x_train)+23)]\n",
        "valid = data_Madrid[(len(x_train)+22):]"
      ],
      "id": "639eb1b5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "f1b12e11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2021-10-15\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "96ca393c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Madrid: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "fc70c8d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Malaga"
      ],
      "id": "e726a796"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Malaga = data_covid.loc[data_covid['provincia'] == 'Málaga']\n",
        "data_Malaga = data_Malaga.set_index('fecha')\n",
        "data_Malaga = data_Malaga.filter(['num_casos'])\n",
        "data_Malaga = data_Malaga[data_Malaga.index < \"2021-12-31\"]\n",
        "data_Malaga"
      ],
      "id": "95f4001d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Malaga.describe()"
      ],
      "id": "14e8e3eb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Malaga = data_Malaga.values"
      ],
      "id": "611b14cc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Malaga = scaler.fit_transform(np_data_Malaga)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Malaga)}')"
      ],
      "id": "77d492ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Malaga_x = []\n",
        "scaled_data_Malaga_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Malaga)):\n",
        "    scaled_data_Malaga_x.append(scaled_data_Malaga[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Malaga_y.append(scaled_data_Malaga[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Malaga_x = np.array(scaled_data_Malaga_x)\n",
        "scaled_data_Malaga_y = np.array(scaled_data_Malaga_y)"
      ],
      "id": "bc9a3d30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Malaga_x[235]"
      ],
      "id": "2fe3992f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Malaga_y[235]"
      ],
      "id": "972b9f9a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Malaga_y)}')"
      ],
      "id": "40bbbeec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Malaga_x[0:len(scaled_data_Malaga_x)-22]\n",
        "y_train = scaled_data_Malaga_y[0:len(scaled_data_Malaga_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Malaga_x[len(scaled_data_Malaga_x)-21:len(scaled_data_Malaga_x)]\n",
        "y_test = scaled_data_Malaga_y[len(scaled_data_Malaga_y)-21:len(scaled_data_Malaga_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "bd997a5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "adbdef38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "bcc0b04e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "f73b8c50",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "70580354",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "f948ae58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "5361532f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "688801f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Malaga[:(len(x_train)+23)]\n",
        "valid = data_Malaga[(len(x_train)+22):]"
      ],
      "id": "57ba6409",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "d338363d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2021-10-15\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "e7d7067d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Malaga: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "51f1a717",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sevilla"
      ],
      "id": "a7bb5ee7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Sevilla = data_covid.loc[data_covid['provincia'] == 'Sevilla']\n",
        "data_Sevilla = data_Sevilla.set_index('fecha')\n",
        "data_Sevilla = data_Sevilla.filter(['num_casos'])\n",
        "data_Sevilla = data_Sevilla[data_Sevilla.index < \"2021-12-31\"]\n",
        "data_Sevilla"
      ],
      "id": "870929c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_Sevilla.describe()"
      ],
      "id": "d1ec9977",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np_data_Sevilla = data_Sevilla.values"
      ],
      "id": "9fb8f199",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data_Sevilla = scaler.fit_transform(np_data_Sevilla)\n",
        "print(f'Longitud del conjunto de datos disponible: {len(scaled_data_Sevilla)}')"
      ],
      "id": "0ca2a34f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since we are going to predict future values based on the X past elements, \n",
        "# we need to create a list with those historic information for each element\n",
        "historic_values = 21\n",
        "scaled_data_Sevilla_x = []\n",
        "scaled_data_Sevilla_y = []\n",
        "\n",
        "for num_casos_i in range(historic_values, len(scaled_data_Sevilla)):\n",
        "    scaled_data_Sevilla_x.append(scaled_data_Sevilla[(num_casos_i-historic_values):num_casos_i, 0])\n",
        "    scaled_data_Sevilla_y.append(scaled_data_Sevilla[num_casos_i, 0])\n",
        "\n",
        "# Convert the x_train and y_train to numpy arrays\n",
        "scaled_data_Sevilla_x = np.array(scaled_data_Sevilla_x)\n",
        "scaled_data_Sevilla_y = np.array(scaled_data_Sevilla_y)"
      ],
      "id": "19903152",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Train data looks like\n",
        "scaled_data_Sevilla_x[235]"
      ],
      "id": "3b4dc4f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test data looks like\n",
        "scaled_data_Sevilla_y[235]"
      ],
      "id": "1298d0bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Since the first 14th values does not have historic, the dataset has been reduced in 14 values\n",
        "print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_Sevilla_y)}')"
      ],
      "id": "b3d87405",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we split data in train and test\n",
        "# as in previous analysis, we are going to predict a maximum of 21 days\n",
        "x_train = scaled_data_Sevilla_x[0:len(scaled_data_Sevilla_x)-22]\n",
        "y_train = scaled_data_Sevilla_y[0:len(scaled_data_Sevilla_y)-22]\n",
        "print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')\n",
        "\n",
        "x_test = scaled_data_Sevilla_x[len(scaled_data_Sevilla_x)-21:len(scaled_data_Sevilla_x)]\n",
        "y_test = scaled_data_Sevilla_y[len(scaled_data_Sevilla_y)-21:len(scaled_data_Sevilla_y)]\n",
        "print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')"
      ],
      "id": "1eecd0c4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Reshape the data to feed de recurrent network\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
        "print(\"Train data shape:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
        "print(\"Test data shape:\")\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "id": "916686f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure / setup the neural network model - LSTM\n",
        "model = Sequential()\n",
        "\n",
        "# Model with Neurons \n",
        "# Inputshape = neurons -> Timestamps\n",
        "neurons= x_train.shape[1]\n",
        "model.add(LSTM(14, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True, \n",
        "               input_shape = (x_train.shape[1], 1))) \n",
        "model.add(LSTM(50, \n",
        "               activation = 'relu',\n",
        "               return_sequences = True)) \n",
        "model.add(LSTM(25, \n",
        "               activation = 'relu',\n",
        "               return_sequences = False)) \n",
        "model.add(Dense(5, activation = 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "id": "3f78093a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training the model\n",
        "# fit network\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    batch_size = 2, \n",
        "                    epochs = 20, \n",
        "                    validation_data = (x_test, y_test), \n",
        "                    verbose = 2)"
      ],
      "id": "3dd09597",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show() "
      ],
      "id": "8ac33662",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the predicted values\n",
        "predictions = model.predict(x_test)\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "predictions"
      ],
      "id": "86f97d24",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "y_test = y_test.reshape(-1,1)\n",
        "y_test = scaler.inverse_transform(y_test)\n",
        "y_test"
      ],
      "id": "a6162863",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print('MAE: ' + str(round(mae, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test,predictions))\n",
        "print('RMSE: ' + str(round(rmse, 1)))\n",
        "\n",
        "# Calculate the root mean squarred error (RMSE)\n",
        "rmse = mean_squared_error(y_test, \n",
        "                          predictions,\n",
        "                          squared = False)\n",
        "print('RMSE: ' + str(round(rmse, 1)))"
      ],
      "id": "b065a01c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Add the difference between the valid and predicted prices\n",
        "train = data_Sevilla[:(len(x_train)+23)]\n",
        "valid = data_Sevilla[(len(x_train)+22):]"
      ],
      "id": "dcd5b66d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "valid.insert(1, \"Predictions\", predictions, True)\n",
        "valid.insert(1, \"Difference\", valid[\"Predictions\"] - valid[\"num_casos\"], True)"
      ],
      "id": "f791404c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Zoom-in to a closer timeframe\n",
        "# Date from which on the date is displayed\n",
        "display_start_date = \"2021-10-15\" \n",
        "valid = valid[valid.index > display_start_date]\n",
        "train = train[train.index > display_start_date]"
      ],
      "id": "154cb6bc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the data\n",
        "matplotlib.style.use('ggplot')\n",
        "fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)\n",
        "\n",
        "# Data - Train\n",
        "xt = train.index; \n",
        "yt = train[[\"num_casos\"]]\n",
        "# Data - Test / validation \n",
        "xv = valid.index; \n",
        "yv = valid[[\"num_casos\", \"Predictions\"]]\n",
        "\n",
        "# Plot\n",
        "plt.title(\"Sevilla: Predictions vs Real infections\", fontsize=20)\n",
        "plt.ylabel(\"Nº Cases\", fontsize=18)\n",
        "\n",
        "plt.plot(yt, color=\"blue\", linewidth=1.5)\n",
        "plt.plot(yv[\"Predictions\"], color=\"red\", linewidth=1.5)\n",
        "plt.plot(yv[\"num_casos\"], color=\"green\", linewidth=1.5)\n",
        "plt.legend([\"Train\", \"LSTM Predictions\", \"Test\"], \n",
        "           loc=\"upper left\", fontsize=18)\n",
        "\n",
        "# Bar plot with the differences\n",
        "x = valid.index\n",
        "y = valid[\"Difference\"]\n",
        "plt.bar(x, y, width=0.2, color=\"grey\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "id": "209d4c88",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}