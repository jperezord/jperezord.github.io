---
output: html_document
editor_options: 
  chunk_output_type: console
---
# LSTM multivariate prediction {.unnumbered}

Import python packages:

```{python}
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

from keras.models import Sequential
from keras.layers import Dense, LSTM
```

```{python}
data_covid = pd.read_csv('data/clean/final_covid_data.csv')
data_covid
```

# All the available data

## Asturias

```{python}
data_asturias = data_covid.loc[data_covid['provincia'] == 'Asturias']
data_asturias = data_asturias.set_index('fecha')
data_asturias = data_asturias[data_asturias.index > "2020-02-15"]
data_asturias
```

```{python}
data = data_asturias.filter(['num_casos', 'tmed', 'mob_grocery_pharmacy', 
'mob_parks', 'mob_residential', 'mob_residential', 'mob_transit_stations', 'mob_workplaces'])
data
```

```{python}
# Train dataset
np_data_asturias = data.values
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data_asturias = scaler.fit_transform(np_data_asturias)
```

```{python}
# Since we are going to predict future values based on the X past elements, 
# we need to create a list with those historic information for each element
historic_values = 21
scaled_data_asturias_x = []
scaled_data_asturias_y = []

for i in range(historic_values, len(scaled_data_asturias)):
    scaled_data_asturias_x.append(scaled_data_asturias[(i-historic_values):i, :])
    scaled_data_asturias_y.append(scaled_data_asturias[i, 0])

# Convert the x_train and y_train to numpy arrays
scaled_data_asturias_x = np.array(scaled_data_asturias_x)
scaled_data_asturias_y = np.array(scaled_data_asturias_y)
```

```{python}
scaled_data_asturias_x[235]
```

```{python}
scaled_data_asturias_y[235]
```

```{python}
# Once predicted, we are going to need a exlucive scaler for num_cases
scaler_pred = MinMaxScaler(feature_range=(0, 1))
df_cases = pd.DataFrame(data_asturias['num_casos'])
scaled_data_asturias_pred = scaler_pred.fit_transform(df_cases)
```

```{python}
# Since the first 14th values does not have historic, the dataset has been reduced in 14 values
print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_asturias_y)}')
```

```{python}
# we split data in train and test
# as in previous analysis, we are going to predict a maximum of 21 days
x_train = scaled_data_asturias_x[0:len(scaled_data_asturias_x)-22]
y_train = scaled_data_asturias_y[0:len(scaled_data_asturias_y)-22]
print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}')

x_test = scaled_data_asturias_x[len(scaled_data_asturias_x)-21:len(scaled_data_asturias_x)]
y_test = scaled_data_asturias_y[len(scaled_data_asturias_y)-21:len(scaled_data_asturias_y)]
print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}')
```

```{python}
# Reshape the data to feed de recurrent network
x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 8))
print("Train data shape:")
print(x_train.shape)
print(y_train.shape)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 8))
print("Test data shape:")
print(x_test.shape)
print(y_test.shape)
```

```{python}
# Configure / setup the neural network model - LSTM
model = Sequential()

# Model with Neurons 
# Inputshape = neurons -> Timestamps
neurons= x_train.shape[1] * x_train.shape[2]
print(neurons, x_train.shape[1], x_train.shape[2])

model.add(LSTM(neurons, 
               activation = 'relu',
               return_sequences = True, 
               input_shape = (x_train.shape[1], x_train.shape[2]))) 
model.add(LSTM(50, 
               activation = 'relu',
               return_sequences = True)) 
model.add(LSTM(25, 
               activation = 'relu',
               return_sequences = False)) 
model.add(Dense(5, activation = 'relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')
```

```{python}
history = model.fit(x_train,
                    y_train,
                    batch_size = 2, 
                    epochs = 20, 
                    validation_data = (x_test, y_test), 
                    verbose = 2)
```

```{python}
plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show() 
```

```{python}
# Get the predicted values
predictions = model.predict(x_test)
predictions = scaler_pred.inverse_transform(predictions)
predictions
```

```{python}
y_test = y_test.reshape(-1,1)
y_test = scaler.inverse_transform(y_test)
y_test
```

```{python}
# Calculate the mean absolute error (MAE)
mae = mean_absolute_error(y_test, predictions)
print('MAE: ' + str(round(mae, 1)))

# Calculate the root mean squarred error (RMSE)
rmse = np.sqrt(mean_squared_error(y_test,predictions))
print('RMSE: ' + str(round(rmse, 1)))

# Calculate the root mean squarred error (RMSE)
rmse = mean_squared_error(y_test, 
                          predictions,
                          squared = False)
print('RMSE: ' + str(round(rmse, 1)))
```

```{python}
# Add the difference between the valid and predicted prices
train = data_asturias[:(len(x_train)+23)]
valid = data_asturias[(len(x_train)+22):]
```

```{python}
valid.insert(1, "Predictions", predictions, True)
valid.insert(1, "Difference", valid["Predictions"] - valid["num_casos"], True)
```

```{python}
# Zoom-in to a closer timeframe
# Date from which on the date is displayed
display_start_date = "2021-10-15" 
valid = valid[valid.index > display_start_date]
train = train[train.index > display_start_date]
```

```{python}
# Visualize the data
matplotlib.style.use('ggplot')
fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True)

# Data - Train
xt = train.index; 
yt = train[["num_casos"]]
# Data - Test / validation 
xv = valid.index; 
yv = valid[["num_casos", "Predictions"]]

# Plot
plt.title("Asturias: Predictions vs Real infections", fontsize=20)
plt.ylabel("NÂº Cases", fontsize=18)

plt.plot(yt, color="blue", linewidth=1.5)
plt.plot(yv["Predictions"], color="red", linewidth=1.5)
plt.plot(yv["num_casos"], color="green", linewidth=1.5)
plt.legend(["Train", "LSTM Predictions", "Test"], 
           loc="upper left", fontsize=18)

# Bar plot with the differences
x = valid.index
y = valid["Difference"]
plt.bar(x, y, width=0.2, color="grey")
plt.grid()
plt.show()
```

```{python}
# ERROR TO FIX
```









<!-- # Just before the sixth wave -->

<!-- ## Asturias -->

<!-- ```{python} -->
<!-- data_asturias = data_covid.loc[data_covid['provincia'] == 'Asturias'] -->
<!-- data_asturias = data_asturias.set_index('fecha') -->
<!-- data_asturias = data_asturias.filter(['num_casos']) -->
<!-- data_asturias = data_asturias[data_asturias.index > "2020-02-15"] -->
<!-- data_asturias = data_asturias[data_asturias.index < "2021-12-31"] -->
<!-- data_asturias -->
<!-- ``` -->

<!-- ```{python} -->
<!-- data_asturias.describe() -->
<!-- ``` -->

<!-- ```{python} -->
<!-- np_data_asturias = data_asturias.values -->
<!-- ``` -->

<!-- ```{python} -->
<!-- scaler = MinMaxScaler(feature_range=(0, 1)) -->
<!-- scaled_data_asturias = scaler.fit_transform(np_data_asturias) -->
<!-- print(f'Longitud del conjunto de datos disponible: {len(scaled_data_asturias)}') -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Since we are going to predict future values based on the X past elements,  -->
<!-- # we need to create a list with those historic information for each element -->
<!-- historic_values = 21 -->
<!-- scaled_data_asturias_x = [] -->
<!-- scaled_data_asturias_y = [] -->

<!-- for num_casos_i in range(historic_values, len(scaled_data_asturias)): -->
<!--     scaled_data_asturias_x.append(scaled_data_asturias[(num_casos_i-historic_values):num_casos_i, 0]) -->
<!--     scaled_data_asturias_y.append(scaled_data_asturias[num_casos_i, 0]) -->

<!-- # Convert the x_train and y_train to numpy arrays -->
<!-- scaled_data_asturias_x = np.array(scaled_data_asturias_x) -->
<!-- scaled_data_asturias_y = np.array(scaled_data_asturias_y) -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Train data looks like -->
<!-- scaled_data_asturias_x[235] -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Test data looks like -->
<!-- scaled_data_asturias_y[235] -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Since the first 14th values does not have historic, the dataset has been reduced in 14 values -->
<!-- print(f'Longitud datos de entrenamiento con historico: {len(scaled_data_asturias_y)}') -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # we split data in train and test -->
<!-- # as in previous analysis, we are going to predict a maximum of 21 days -->
<!-- x_train = scaled_data_asturias_x[0:len(scaled_data_asturias_x)-22] -->
<!-- y_train = scaled_data_asturias_y[0:len(scaled_data_asturias_y)-22] -->
<!-- print(f'Cantidad datos de entrenamiento: x={len(x_train)} - y={len(y_train)}') -->

<!-- x_test = scaled_data_asturias_x[len(scaled_data_asturias_x)-21:len(scaled_data_asturias_x)] -->
<!-- y_test = scaled_data_asturias_y[len(scaled_data_asturias_y)-21:len(scaled_data_asturias_y)] -->
<!-- print(f'Cantidad datos de test: x={len(x_test)} - y={len(y_test)}') -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Reshape the data to feed de recurrent network -->
<!-- x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1)) -->
<!-- print("Train data shape:") -->
<!-- print(x_train.shape) -->
<!-- print(y_train.shape) -->
<!-- x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1)) -->
<!-- print("Test data shape:") -->
<!-- print(x_test.shape) -->
<!-- print(y_test.shape) -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Configure / setup the neural network model - LSTM -->
<!-- model = Sequential() -->

<!-- # Model with Neurons  -->
<!-- # Inputshape = neurons -> Timestamps -->
<!-- neurons= x_train.shape[1] -->
<!-- model.add(LSTM(14,  -->
<!--                activation = 'relu', -->
<!--                return_sequences = True,  -->
<!--                input_shape = (x_train.shape[1], 1)))  -->
<!-- model.add(LSTM(50,  -->
<!--                activation = 'relu', -->
<!--                return_sequences = True))  -->
<!-- model.add(LSTM(25,  -->
<!--                activation = 'relu', -->
<!--                return_sequences = False))  -->
<!-- model.add(Dense(5, activation = 'relu')) -->
<!-- model.add(Dense(1)) -->

<!-- # Compile the model -->
<!-- model.compile(optimizer='adam', loss='mean_squared_error') -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Training the model -->
<!-- # fit network -->
<!-- history = model.fit(x_train, -->
<!--                     y_train, -->
<!--                     batch_size = 2,  -->
<!--                     epochs = 20,  -->
<!--                     validation_data = (x_test, y_test),  -->
<!--                     verbose = 2) -->
<!-- ``` -->

<!-- ```{python} -->
<!-- plt.plot(history.history['loss'], label='train') -->
<!-- plt.plot(history.history['val_loss'], label='test') -->
<!-- plt.legend() -->
<!-- plt.show()  -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Get the predicted values -->
<!-- predictions = model.predict(x_test) -->
<!-- predictions = scaler.inverse_transform(predictions) -->
<!-- predictions -->
<!-- ``` -->

<!-- ```{python} -->
<!-- y_test = y_test.reshape(-1,1) -->
<!-- y_test = scaler.inverse_transform(y_test) -->
<!-- y_test -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Calculate the mean absolute error (MAE) -->
<!-- mae = mean_absolute_error(y_test, predictions) -->
<!-- print('MAE: ' + str(round(mae, 1))) -->

<!-- # Calculate the root mean squarred error (RMSE) -->
<!-- rmse = np.sqrt(mean_squared_error(y_test,predictions)) -->
<!-- print('RMSE: ' + str(round(rmse, 1))) -->

<!-- # Calculate the root mean squarred error (RMSE) -->
<!-- rmse = mean_squared_error(y_test,  -->
<!--                           predictions, -->
<!--                           squared = False) -->
<!-- print('RMSE: ' + str(round(rmse, 1))) -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Add the difference between the valid and predicted prices -->
<!-- train = data_asturias[:(len(x_train)+23)] -->
<!-- valid = data_asturias[(len(x_train)+22):] -->
<!-- ``` -->

<!-- ```{python} -->
<!-- valid.insert(1, "Predictions", predictions, True) -->
<!-- valid.insert(1, "Difference", valid["Predictions"] - valid["num_casos"], True) -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Zoom-in to a closer timeframe -->
<!-- # Date from which on the date is displayed -->
<!-- display_start_date = "2021-10-15"  -->
<!-- valid = valid[valid.index > display_start_date] -->
<!-- train = train[train.index > display_start_date] -->
<!-- ``` -->

<!-- ```{python} -->
<!-- # Visualize the data -->
<!-- matplotlib.style.use('ggplot') -->
<!-- fig, ax1 = plt.subplots(figsize=(22, 10), sharex=True) -->

<!-- # Data - Train -->
<!-- xt = train.index;  -->
<!-- yt = train[["num_casos"]] -->
<!-- # Data - Test / validation  -->
<!-- xv = valid.index;  -->
<!-- yv = valid[["num_casos", "Predictions"]] -->

<!-- # Plot -->
<!-- plt.title("Asturias: Predictions vs Real infections", fontsize=20) -->
<!-- plt.ylabel("NÂº Cases", fontsize=18) -->

<!-- plt.plot(yt, color="blue", linewidth=1.5) -->
<!-- plt.plot(yv["Predictions"], color="red", linewidth=1.5) -->
<!-- plt.plot(yv["num_casos"], color="green", linewidth=1.5) -->
<!-- plt.legend(["Train", "LSTM Predictions", "Test"],  -->
<!--            loc="upper left", fontsize=18) -->

<!-- # Bar plot with the differences -->
<!-- x = valid.index -->
<!-- y = valid["Difference"] -->
<!-- plt.bar(x, y, width=0.2, color="grey") -->
<!-- plt.grid() -->
<!-- plt.show() -->
<!-- ``` -->

